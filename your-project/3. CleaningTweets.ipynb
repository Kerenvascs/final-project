{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\My Probook\n",
      "[nltk_data]     G2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast, json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "# Import Punkt\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>city</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>link</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>New York</td>\n",
       "      <td>@UberEats Promo Code never works for 50%. what...</td>\n",
       "      <td>2020-07-14 23:57:38+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/FashionsWeek/status/128318...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>Yea they’re terrible smh. @UberEats @Uber_Support</td>\n",
       "      <td>2020-07-14 23:36:33+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/kensthetic_/status/1283183...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>New York</td>\n",
       "      <td>@UberEats when are you coming to upstate ny?</td>\n",
       "      <td>2020-07-14 23:33:33+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/Thebobover/status/12831828...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>New York</td>\n",
       "      <td>@diginn why does the dig inn app and @UberEats...</td>\n",
       "      <td>2020-07-14 23:30:41+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/Hot4TaterTots/status/12831...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>New York</td>\n",
       "      <td>For my brother to have his Uber job back! He h...</td>\n",
       "      <td>2020-07-14 23:04:47+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/Rayofshine69/status/128317...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_count      city                                               body  \\\n",
       "0            0  New York  @UberEats Promo Code never works for 50%. what...   \n",
       "1            1  New York  Yea they’re terrible smh. @UberEats @Uber_Support   \n",
       "2            2  New York       @UberEats when are you coming to upstate ny?   \n",
       "3            3  New York  @diginn why does the dig inn app and @UberEats...   \n",
       "4            4  New York  For my brother to have his Uber job back! He h...   \n",
       "\n",
       "                        date hashtags  \\\n",
       "0  2020-07-14 23:57:38+00:00      NaN   \n",
       "1  2020-07-14 23:36:33+00:00      NaN   \n",
       "2  2020-07-14 23:33:33+00:00      NaN   \n",
       "3  2020-07-14 23:30:41+00:00      NaN   \n",
       "4  2020-07-14 23:04:47+00:00      NaN   \n",
       "\n",
       "                                                link  geo  \n",
       "0  https://twitter.com/FashionsWeek/status/128318...  NaN  \n",
       "1  https://twitter.com/kensthetic_/status/1283183...  NaN  \n",
       "2  https://twitter.com/Thebobover/status/12831828...  NaN  \n",
       "3  https://twitter.com/Hot4TaterTots/status/12831...  NaN  \n",
       "4  https://twitter.com/Rayofshine69/status/128317...  NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df= pd.read_csv('old_tweets.csv')\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_count       0\n",
       "city              0\n",
       "body              5\n",
       "date              0\n",
       "hashtags       2186\n",
       "link              0\n",
       "geo            3013\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.dropna(subset=['body'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3008, 7)\n"
     ]
    }
   ],
   "source": [
    "tweets_df.isnull().sum()\n",
    "print(tweets_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>city</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>link</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>New York</td>\n",
       "      <td>@UberEats Promo Code never works for 50%. what...</td>\n",
       "      <td>2020-07-14 23:57:38+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/FashionsWeek/status/128318...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>Yea they’re terrible smh. @UberEats @Uber_Support</td>\n",
       "      <td>2020-07-14 23:36:33+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/kensthetic_/status/1283183...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>New York</td>\n",
       "      <td>@UberEats when are you coming to upstate ny?</td>\n",
       "      <td>2020-07-14 23:33:33+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/Thebobover/status/12831828...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>New York</td>\n",
       "      <td>@diginn why does the dig inn app and @UberEats...</td>\n",
       "      <td>2020-07-14 23:30:41+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/Hot4TaterTots/status/12831...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>New York</td>\n",
       "      <td>For my brother to have his Uber job back! He h...</td>\n",
       "      <td>2020-07-14 23:04:47+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/Rayofshine69/status/128317...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_count      city                                               body  \\\n",
       "0            0  New York  @UberEats Promo Code never works for 50%. what...   \n",
       "1            1  New York  Yea they’re terrible smh. @UberEats @Uber_Support   \n",
       "2            2  New York       @UberEats when are you coming to upstate ny?   \n",
       "3            3  New York  @diginn why does the dig inn app and @UberEats...   \n",
       "4            4  New York  For my brother to have his Uber job back! He h...   \n",
       "\n",
       "                        date hashtags  \\\n",
       "0  2020-07-14 23:57:38+00:00      NaN   \n",
       "1  2020-07-14 23:36:33+00:00      NaN   \n",
       "2  2020-07-14 23:33:33+00:00      NaN   \n",
       "3  2020-07-14 23:30:41+00:00      NaN   \n",
       "4  2020-07-14 23:04:47+00:00      NaN   \n",
       "\n",
       "                                                link  geo  \n",
       "0  https://twitter.com/FashionsWeek/status/128318...  NaN  \n",
       "1  https://twitter.com/kensthetic_/status/1283183...  NaN  \n",
       "2  https://twitter.com/Thebobover/status/12831828...  NaN  \n",
       "3  https://twitter.com/Hot4TaterTots/status/12831...  NaN  \n",
       "4  https://twitter.com/Rayofshine69/status/128317...  NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.drop_duplicates(subset ='body', \n",
    "                     keep = False, inplace = True) \n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2975, 7)\n"
     ]
    }
   ],
   "source": [
    "print(tweets_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tokenizer + Lematizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to tokenize the sentences\n",
    "def tokenize_cleaner(x):\n",
    "    x = str(x)\n",
    "    mylist =  word_tokenize(x)\n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>city</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>link</th>\n",
       "      <th>geo</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>New York</td>\n",
       "      <td>@UberEats Promo Code never works for 50%. what...</td>\n",
       "      <td>2020-07-14 23:57:38+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/FashionsWeek/status/128318...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[@, UberEats, Promo, Code, never, works, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>Yea they’re terrible smh. @UberEats @Uber_Support</td>\n",
       "      <td>2020-07-14 23:36:33+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/kensthetic_/status/1283183...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Yea, they, ’, re, terrible, smh, ., @, UberEa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_count      city                                               body  \\\n",
       "0            0  New York  @UberEats Promo Code never works for 50%. what...   \n",
       "1            1  New York  Yea they’re terrible smh. @UberEats @Uber_Support   \n",
       "\n",
       "                        date hashtags  \\\n",
       "0  2020-07-14 23:57:38+00:00      NaN   \n",
       "1  2020-07-14 23:36:33+00:00      NaN   \n",
       "\n",
       "                                                link  geo  \\\n",
       "0  https://twitter.com/FashionsWeek/status/128318...  NaN   \n",
       "1  https://twitter.com/kensthetic_/status/1283183...  NaN   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [@, UberEats, Promo, Code, never, works, for, ...  \n",
       "1  [Yea, they, ’, re, terrible, smh, ., @, UberEa...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['tokenized'] = tweets_df['body'].apply(tokenize_cleaner) \n",
    "tweets_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\My Probook\n",
      "[nltk_data]     G2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\My Probook G2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wordnet is a lexical database for the English language that helps the script determine the base word. \n",
    "# You need the averaged_perceptron_tagger resource to determine the context of a word in a sentence\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Remove the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "def remove_noise(tweet_tokens, stop_words = ()):\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ubereats', 'promo', 'code', 'never', 'work', 'for', '50', 'what', 'do', 'i', 'do']\n"
     ]
    }
   ],
   "source": [
    "tweets_df['cleaned'] = tweets_df['tokenized'].apply(remove_noise)\n",
    "tweets_df.head(2)\n",
    "print(tweets_df['cleaned'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download stopwords\n",
    "# In addition to this, you will also remove stop words using a built-in set of stop words in NLTK, \n",
    "# which needs to be downloaded separately\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopword(x):\n",
    "    return [word for word in x if word not in stop_words]\n",
    "\n",
    "tweets_df['cleaned'] = tweets_df['cleaned'].apply(lambda x:remove_stopword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ubereats', 'promo', 'code', 'never', 'work', '50']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['cleaned'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df.to_csv('UberEats.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
